<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students 2025" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group LingoBingo, Progress Report, " />

<meta property="og:title" content="Fed Watching: Web Scraping and Data Preprocessing (by Group &#34;LingoBingo&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/fed-watching-web-scraping-and-data-preprocessing-by-group-lingobingo.html" />
<meta property="og:description" content="Introduction The Fed Funds Rate is a benchmark interest rate that influences monetary policy, economic management, financial markets, asset prices, and has a global impact. Its importance is therefore evident, making the study of factors related to the Fed Funds Rate highly meaningful. Our project aims to analyze Federal textual …" />
<meta property="og:site_name" content="MFIN7036 Student Blog 2025" />
<meta property="og:article:author" content="MFIN7036 Students 2025" />
<meta property="og:article:published_time" content="2025-02-23T15:00:00+08:00" />
<meta name="twitter:title" content="Fed Watching: Web Scraping and Data Preprocessing (by Group &#34;LingoBingo&#34;) ">
<meta name="twitter:description" content="Introduction The Fed Funds Rate is a benchmark interest rate that influences monetary policy, economic management, financial markets, asset prices, and has a global impact. Its importance is therefore evident, making the study of factors related to the Fed Funds Rate highly meaningful. Our project aims to analyze Federal textual …">

        <title>Fed Watching: Web Scraping and Data Preprocessing (by Group &#34;LingoBingo&#34;)  · MFIN7036 Student Blog 2025
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog 2025 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/"><span class=site-name>MFIN7036 Student Blog 2025</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2025-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/fed-watching-web-scraping-and-data-preprocessing-by-group-lingobingo.html">
                Fed Watching: Web Scraping and Data Preprocessing (by Group "LingoBingo")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <h2>Introduction</h2>
<p>The Fed Funds Rate is a benchmark interest rate that influences monetary policy, economic management, financial markets, asset prices, and has a global impact. Its importance is therefore evident, making the study of factors related to the Fed Funds Rate highly meaningful. </p>
<p>Our project aims to analyze Federal textual information to predict future rate using text analysis and NLP. We will base our analysis on text data from FOMC statements, minutes, SEP reports, and public speeches by officials.</p>
<p>Recent studies have consistently highlighted the critical role of Federal Reserve communications in shaping the Fed Funds Rate by influencing beliefs about monetary policy and other economic fundamentals. Our project will use the latest data to explore the relationship between Federal textual information and the Fed Funds Rate.</p>
<p>We have performed data preprocessing and constructed a FOMC text dataset to provide a high-quality foundation for subsequent interest rate prediction models. This blog will focus on our data collection, preprocessing, and database establishment processes.</p>
<h2>Data Collection</h2>
<h3>Financial Data</h3>
<p>We obtain the data for both the federal funds target rate and the effective federal funds rate by directly downloading it from <a href="https://fred.stlouisfed.org/">the Federal Reserve Bank of St. Louis website</a>.</p>
<h3>Text Data</h3>
<p>We obtain text data from FOMC statements, minutes, SEP reports, and public speeches by officials through <a href="https://www.federalreserve.gov">the official website of the Federal Reserve</a>.</p>
<p>The following table summarizes the basic information for the various documents that we analyze.</p>
<p><img alt="Table: Text Data Info" src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/images/LingoBingo_Text-Data_image-description.png"></p>
<p>We collect text data through web crawling using Python. The specific process is as follows:</p>
<ul>
<li>Import libraries</li>
</ul>
<p>We use Python's <code>Requests</code> and <code>BeautifulSoup</code> libraries to parse HTML pages and combine them with <code>PyPDF2</code> to process PDF documents. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">PyPDF2</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>
<span class="kn">import</span> <span class="nn">re</span> 
<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urljoin</span>
</code></pre></div>

<ul>
<li>Data Scraping</li>
</ul>
<p>The time range of the project spans from 2000 to 2024. However, before 2020, statements, minutes, seps and transcripts had a different URL format. Therefore, we need two different URLs. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># URLs for current and historical FOMC data</span>
<span class="n">current_url</span> <span class="o">=</span> <span class="s2">&quot;https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm&quot;</span>
<span class="n">historical_url</span> <span class="o">=</span> <span class="s2">&quot;https://www.federalreserve.gov/monetarypolicy/fomc_historical_year.htm&quot;</span>
</code></pre></div>

<p>The original text often contains garbled characters due to encoding errors. To handle disturbances from special characters and redundant spaces, we have also defined a function to perform data cleaning.The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\xa0</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>   <span class="c1">#Replace non line breaking spaces with regular spaces</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x93</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">)</span>   <span class="c1"># Fix encoding errors for short dashes (-)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x99</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">)</span>   <span class="c1"># Fix the encoding error of the right single quotation mark (&#39;)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x94</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">)</span>   <span class="c1"># Fix encoding errors for long dashes (-)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x9c</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">)</span>   <span class="c1"># Fix encoding error of left double quotation mark (&quot;)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x9d</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">)</span>   <span class="c1"># Fix encoding error of left double quotation mark (&quot;)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x98</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">)</span>    <span class="c1"># Fix encoding error of left single quotation mark (&#39;)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x9e</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">)</span>   <span class="c1"># Fix encoding errors of double quotation marks („) (some language usage)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x9f</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">)</span>   <span class="c1"># Fix encoding errors in double quotes (‟)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;â</span><span class="se">\x80\x91</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">)</span>   <span class="c1"># Fix encoding errors for hyphens (-)</span>

    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>   <span class="c1">#Merge consecutive whitespace characters into a single space and remove the leading and trailing spaces</span>

    <span class="k">return</span> <span class="n">text</span>
</code></pre></div>

<p>Next, we define two functions(<code>scrape_fomc_historical_data(url)</code> and <code>scrape_fomc_data(url)</code>) to scrape data.
In these functions, we first make a GET request to the incoming URL to retrieve the page content, which is then parsed using BeautifulSoup. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Then, the functions traverse all the links on the page and determine the type of document based on the 'href' attribute of each link: statements, minutes, transcripts, or SEP.</p>
<p>Since we use two URLs to obtain data from different time frames, we merge the results after scraping the data. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Scrape data from the current FOMC calendar</span>
<span class="n">current_statements</span><span class="p">,</span> <span class="n">current_minutes</span><span class="p">,</span> <span class="n">current_seps</span> <span class="o">=</span> <span class="n">scrape_fomc_data</span><span class="p">(</span><span class="n">current_url</span><span class="p">)</span>
<span class="c1"># Scrape data from the historical FOMC calendar</span>
<span class="n">historical_statements</span><span class="p">,</span> <span class="n">historical_minutes</span><span class="p">,</span> <span class="n">historical_seps</span><span class="p">,</span> <span class="n">transcripts</span> <span class="o">=</span> <span class="n">scrape_fomc_historical_data</span><span class="p">(</span><span class="n">historical_url</span><span class="p">)</span>
<span class="c1"># Combine the results</span>
<span class="n">statements</span> <span class="o">=</span> <span class="n">current_statements</span> <span class="o">+</span> <span class="n">historical_statements</span>
<span class="n">minutes</span> <span class="o">=</span> <span class="n">current_minutes</span> <span class="o">+</span> <span class="n">historical_minutes</span>
<span class="c1"># Filling a little bug...(some dates have the length of 7 ...)</span>
<span class="n">minutes</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">minutes</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">seps</span> <span class="o">=</span> <span class="n">current_seps</span> <span class="o">+</span> <span class="n">historical_seps</span>
</code></pre></div>

<p>Finally, we structure the data by organizing each text source into a table, which includes the time and the corresponding text. Then, we export the data to Excel. A sample output is shown below:</p>
<p><img alt="Picture: Sample Output" src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/images/LingoBingo_Sample-Output_image-description.png"></p>
<h2>Data Preprocessing</h2>
<p>To maintain the integrity of data, we preprocess statements, minutes, seps and transcripts separately.</p>
<p>Tokenization, stemming, and lemmatization help extract key emotional vocabulary and enhance the model's ability to understand policy texts, thereby improving the accuracy of sentiment classification. These are important steps in the preprocessing phase. We use the NLTK package to perform these tasks.</p>
<p>First, we import NLTK package and download essential sources. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;wordnet&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt_tab&#39;</span><span class="p">)</span>
</code></pre></div>

<p>Then take the statements as an example to show our codes for performing tokenization, lower case conversion, punctuation removal, stop word removal, stemming, and lemmatization. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">statements</span> <span class="ow">in</span> <span class="n">statements</span><span class="p">:</span>

    <span class="c1"># read the text in statements into value</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">statements</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span>

    <span class="c1"># Tokenization + Lower Case Conversion + Remove Punctuation</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()]</span>

    <span class="c1">#  Stop Word Removal</span>
    <span class="n">no_stops</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)]</span> 

    <span class="c1">#  Stemming</span>
    <span class="n">stems</span> <span class="o">=</span> <span class="p">[</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">no_stops</span><span class="p">]</span>

    <span class="c1"># Lemmatization</span>
    <span class="n">lemmas</span> <span class="o">=</span> <span class="p">[</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">no_stops</span><span class="p">]</span>

    <span class="c1"># store into new_statements</span>
    <span class="n">new_statements</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">statements</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">],</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">statements</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">],</span>
        <span class="s1">&#39;original&#39;</span><span class="p">:</span> <span class="n">value</span><span class="p">,</span>
        <span class="s1">&#39;tokenized&#39;</span><span class="p">:</span> <span class="n">words</span><span class="p">,</span>
        <span class="s1">&#39;stems&#39;</span><span class="p">:</span> <span class="n">stems</span><span class="p">,</span>
        <span class="s1">&#39;lemmas&#39;</span><span class="p">:</span> <span class="n">lemmas</span>
    <span class="p">})</span>
</code></pre></div>

<p>In future work, we will perform additional preprocessing steps, such as using n-Grams, to further enhance the precision and reliability of our project.</p>
<h2>Database Establishment</h2>
<p>To facilitate further analysis, we create two SQLite databases(<code>FOMC_lemmas_data</code> and <code>FOMC_stems_data</code>) to store the processed data. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">sqlite3</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s1">&#39;FOMC_lemmas_data.db&#39;</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s1">&#39;FOMC_stems_data.db&#39;</span><span class="p">)</span>

<span class="c1"># create a cursor</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

<span class="c1"># create a table for lemmas</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">CREATE TABLE IF NOT EXISTS FOMC_lemmas_features (</span>
<span class="s1">    id INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s1">    type TEXT NOT NULL,</span>
<span class="s1">    date TEXT NOT NULL,</span>
<span class="s1">    lemmas TEXT NOT NULL</span>
<span class="s1">)</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>

<span class="c1"># create a table for stems</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">CREATE TABLE IF NOT EXISTS FOMC_stems_features (</span>
<span class="s1">    id INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s1">    type TEXT NOT NULL,</span>
<span class="s1">    date TEXT NOT NULL,</span>
<span class="s1">    stems TEXT NOT NULL</span>
<span class="s1">)</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>

<span class="c1"># define a function to insert lemmas</span>
<span class="k">def</span> <span class="nf">insert_lemmas</span><span class="p">(</span><span class="n">data_list</span><span class="p">):</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">executemany</span><span class="p">(</span>
        <span class="s1">&#39;INSERT INTO FOMC_lemmas_features (type, date, lemmas) VALUES (?, ?, ?)&#39;</span><span class="p">,</span> 
        <span class="p">[(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">],</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;lemmas&quot;</span><span class="p">]))</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">]</span>
    <span class="p">)</span>

<span class="c1"># define a function to insert stems</span>
<span class="k">def</span> <span class="nf">insert_stems</span><span class="p">(</span><span class="n">data_list</span><span class="p">):</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">executemany</span><span class="p">(</span>
        <span class="s1">&#39;INSERT INTO FOMC_stems_features (type, date, stems) VALUES (?, ?, ?)&#39;</span><span class="p">,</span> 
        <span class="p">[(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">],</span> <span class="n">item</span><span class="p">[</span><span class="s2">&quot;date&quot;</span><span class="p">],</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s2">&quot;stems&quot;</span><span class="p">]))</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">]</span>
    <span class="p">)</span>

<span class="c1"># insert our lemmas</span>
<span class="n">insert_lemmas</span><span class="p">(</span><span class="n">new_seps</span><span class="p">)</span>
<span class="n">insert_lemmas</span><span class="p">(</span><span class="n">new_minutes</span><span class="p">)</span>
<span class="n">insert_lemmas</span><span class="p">(</span><span class="n">new_statements</span><span class="p">)</span>
<span class="n">insert_lemmas</span><span class="p">(</span><span class="n">new_transcripts</span><span class="p">)</span>

<span class="c1"># insert our stems</span>
<span class="n">insert_stems</span><span class="p">(</span><span class="n">new_seps</span><span class="p">)</span>
<span class="n">insert_stems</span><span class="p">(</span><span class="n">new_minutes</span><span class="p">)</span>
<span class="n">insert_stems</span><span class="p">(</span><span class="n">new_statements</span><span class="p">)</span>
<span class="n">insert_stems</span><span class="p">(</span><span class="n">new_transcripts</span><span class="p">)</span>

<span class="c1"># commit the transaction</span>
<span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>

<span class="c1"># close the cursor and connect</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>

<h2>Word Cloud</h2>
<p>To gain an overview of our textual data, we create word clouds based on the two aforementioned databases, which are useful tools for quickly identifying high-frequency words within a body of text. The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>

<span class="c1"># Combine all texts</span>
<span class="n">all_texts</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#if we use stems for further analysis</span>
<span class="c1">#for lst in [stems]:</span>

<span class="c1">#if we use lemmas for further analysis</span>
<span class="k">for</span> <span class="n">lst</span> <span class="ow">in</span> <span class="p">[</span><span class="n">lemmas</span><span class="p">]:</span>   
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
        <span class="c1"># Ensure the item is a tuple and has at least 4 elements</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>  <span class="c1"># Get the fourth index (value at index 3)</span>
            <span class="c1"># Ensure &#39;text&#39; is a string</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">all_texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Non-string data: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Item is not a valid tuple: </span><span class="si">{</span><span class="n">item</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Join the texts into a single string</span>
<span class="n">text_string</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">all_texts</span><span class="p">)</span>

<span class="c1"># Generate the word cloud</span>
<span class="n">wordcloud</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">background_color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">text_string</span><span class="p">)</span>

<span class="c1"># Display the word cloud</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wordcloud</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  <span class="c1"># Hide the axes</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>

<p>We generate two word clouds as follows, highlighting key metrics that the FOMC pays significant attention to, such as monetary policy and the labor market.</p>
<p><img alt="Picture: Word Could_Stem" src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/images/LingoBingo_Word-Cloud-Stem_image-description.png">             </p>
<p><img alt="Picture: Word Could_Lemmas" src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/images/LingoBingo_Word-Cloud-Lemmas_image-description.png"></p>
<h2>Future Directions</h2>
<ul>
<li>
<p>Perform more comprehensive data preprocessing.</p>
</li>
<li>
<p>Perform sentiment analysis to obtain polarity scores.</p>
</li>
<li>
<p>Apply machine learning to establish a relationship between the Fed Funds Rate and polarity scores. Then, use our trained model to predict the Fed Funds Rate.</p>
</li>
</ul>
<p>We will share more details in our next blog post. Thank you for reading our blog!</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2025-02-23T15:00:00+08:00">Sun 23 February 2025</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/categories.html#progress-report-ref">Progress Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/tags.html#group-lingobingo-ref">Group LingoBingo
                    <span class="superscript">1</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2025-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2025-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>